# -*- coding: utf-8 -*-
"""Image_Classification_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r3vDSvhruqDj12Cw2MRh4pj6b0E0-d10

# **Image Classification using Convolutional Neural Networks (CNNs)**

**Dataset Source** : https://www.kaggle.com/datasets/puneet6060/intel-image-classification

**About Dataset**  

The dataset comprises image data capturing natural scenes from various locations worldwide. It contains approximately **25,000** images, each sized 150x150 pixels, categorized into six distinct classes:

- Buildings (category 0)
- Forest (category 1)
- Glacier (category 2)
- Mountain (category 3)
- Sea (category 4)
- Street (category 5)

The dataset is divided into three main subsets: Train, Test, and Prediction. Each subset is stored in separate zip files. Specifically, there are about 14,000 images in the Train set, 3,000 images in the Test set, and 7,000 images in the Prediction set.

This dataset provides a diverse collection of natural scene images, making it suitable for various computer vision tasks such as image classification, object detection, and scene recognition.

**1. Import the Required Libraries**
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import os
import warnings
warnings.filterwarnings('ignore')

from sklearn.metrics import confusion_matrix, classification_report

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping

!pip install kaggle

from google.colab import files
files.upload()  # Uploading Kaggle API token (kaggle.json)
!mkdir ~/.kaggle
!mv kaggle.json ~/.kaggle/
!kaggle datasets download -d puneet6060/intel-image-classification

!unzip intel-image-classification.zip

"""# **2. Data Preprocessing**

**i. Get the Image Dataset Paths**
"""

train_dataset_path = '/content/seg_train/seg_train'
validation_dataset_path = '/content/seg_test/seg_test'

"""**ii. Load Image Datasets and Apply Augmentations**"""

IMG_WIDTH = 150
IMG_HEIGHT = 150
BATCH_SIZE = 32

"""***Loading the training dataset and applying augmentations on it***"""

train_datagen = ImageDataGenerator(rescale=1.0/255,  # Normalize pixel values
                                  zoom_range=0.2,    # Zoom in or out by up to 20%
                                  width_shift_range=0.2,    # Shift images horizontally by up to 20% of the width
                                  height_shift_range=0.2,   # Shift images vertically by up to 20% of the height
                                  fill_mode='nearest')      # Fill in missing pixels with the nearest value
train_generator = train_datagen.flow_from_directory(train_dataset_path,
                                                   target_size=(IMG_WIDTH, IMG_HEIGHT),
                                                   batch_size=BATCH_SIZE,
                                                   class_mode='categorical',
                                                   shuffle=True)

"""***Loading the validation dataset***"""

validation_datagen = ImageDataGenerator(rescale=1.0/255)
validation_generator = validation_datagen.flow_from_directory(validation_dataset_path,
                                                             target_size=(IMG_WIDTH, IMG_HEIGHT),
                                                             batch_size=BATCH_SIZE,
                                                             class_mode='categorical',
                                                             shuffle=True)

"""**iii. Get the Label Mappings**"""

labels = {value: key for key, value in train_generator.class_indices.items()}

print("Label Mappings for classes present in the training and validation datasets\n")
for key, value in labels.items():
    print(f"{key} : {value}")

# Showing classes of images and distribution of images in train and test datasets
cat = os.listdir(train_dataset_path)
num_train = {}
num_test = {}

for c in cat:
    num_train[c] = len(os.listdir(train_dataset_path + "/" + c))
    num_test[c] = len(os.listdir(validation_dataset_path + "/" + c))


fig = plt.figure(figsize=(13, 4))
t = ('Train', 'Test')
for i, d in enumerate((num_train, num_test), start=1):
    plt.subplot(1, 2, i)
    plt.bar(tuple(d.keys()), tuple(d.values()), color='royalblue')
    plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)
    plt.title(t[i-1])
plt.show()

"""**3. Plotting Sample Training Images**"""

fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(15, 12))
idx = 0

for i in range(2):
    for j in range(5):
        label = labels[np.argmax(train_generator[0][1][idx])]
        ax[i, j].set_title(f"{label}")
        ax[i, j].imshow(train_generator[0][0][idx][:, :, :])
        ax[i, j].axis("off")
        idx += 1

plt.tight_layout()
plt.suptitle("Sample Training Images", fontsize=21)
plt.show()

"""# **4. Training a CNN Model**

**i. Create a CNN Model**
"""

def create_model():       # Defining the model
    model = Sequential([
        Conv2D(filters=128, kernel_size=(5, 5), padding='valid', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),
        Activation('relu'),
        MaxPooling2D(pool_size=(2, 2)),
        BatchNormalization(),

        Conv2D(filters=64, kernel_size=(3, 3), padding='valid', kernel_regularizer=l2(0.00005)),
        Activation('relu'),
        MaxPooling2D(pool_size=(2, 2)),
        BatchNormalization(),

        Conv2D(filters=32, kernel_size=(3, 3), padding='valid', kernel_regularizer=l2(0.00005)),
        Activation('relu'),
        MaxPooling2D(pool_size=(2, 2)),
        BatchNormalization(),

        Flatten(),

        Dense(units=256, activation='relu'),
        Dropout(0.5),
        Dense(units=6, activation='softmax')
    ])

    return model

cnn_model = create_model()   # Creating the model

print(cnn_model.summary())   # Printing the model summary

"""**ii. Reduce Learning Rate on Plateau**

This is a callback object and is used to reduce the learning rate when a metric has stopped improving
"""

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5)

"""**iii. Defining the Optimizer**"""

optimizer = Adam(learning_rate=0.001)

"""**iv. Compile the Model**"""

cnn_model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(), metrics=['accuracy'])

"""**v. Training the Model**"""

history = cnn_model.fit(train_generator, epochs=20, validation_data=validation_generator,
                       verbose=2,
                       callbacks=[reduce_lr])

"""**It took 24 minutes to train the CNN model**

**vi. Plotting training and validation accuracy, loss and learning rate**
"""

train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

train_loss = history.history['loss']
val_loss = history.history['val_loss']

learning_rate = history.history['lr']

fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(6, 6))

ax[0].set_title('Training Accuracy vs. Epochs')
ax[0].plot(train_accuracy, 'o-', label='Train Accuracy')
ax[0].plot(val_accuracy, 'o-', label='Validation Accuracy')
ax[0].set_xlabel('Epochs')
ax[0].set_ylabel('Accuracy')
ax[0].legend(loc='best')

ax[1].set_title('Training/Validation Loss vs. Epochs')
ax[1].plot(train_loss, 'o-', label='Train Loss')
ax[1].plot(val_loss, 'o-', label='Validation Loss')
ax[1].set_xlabel('Epochs')
ax[1].set_ylabel('Loss')
ax[1].legend(loc='best')

ax[2].set_title('Learning Rate vs. Epochs')
ax[2].plot(learning_rate, 'o-', label='Learning Rate')
ax[2].set_xlabel('Epochs')
ax[2].set_ylabel('Loss')
ax[2].legend(loc='best')

plt.tight_layout()
plt.show()

"""# **5. Evaluation**

**Testing the Model on Test Set**
"""

test_dataset = '/content/seg_test/seg_test/'

test_datagen = ImageDataGenerator(rescale=1.0/255)

test_generator = test_datagen.flow_from_directory(test_dataset,
                                                 shuffle=False,
                                                 batch_size=BATCH_SIZE,
                                                 target_size = (IMG_WIDTH, IMG_HEIGHT),
                                                 class_mode='categorical')

"""**Model Prediction on the Test Dataset**"""

predictions = cnn_model.predict(test_generator)

fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(12, 10))   # Plotting the test data predictions
idx = 0

for i in range(2):
    for j in range(5):
        predicted_label = labels[np.argmax(predictions[idx])]
        ax[i, j].set_title(f"{predicted_label}")
        ax[i, j].imshow(test_generator[0][0][idx])
        ax[i, j].axis("off")
        idx += 1

plt.tight_layout()
plt.suptitle("Test Dataset Predictions", fontsize=20)
plt.show()

test_loss, test_accuracy = cnn_model.evaluate(test_generator, batch_size=BATCH_SIZE)

print(f"Test Loss:     {test_loss}")      # Printing the test loss and test accuracy
print(f"Test Accuracy: {test_accuracy}")

"""**Plotting the Classification Metrics**"""

y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes

print(classification_report(y_true, y_pred, target_names=labels.values()))

"""**Confusion Matrix**"""

cf_mtx = confusion_matrix(y_true, y_pred)    # Plotting the confusion matrix

group_counts = ["{0:0.0f}".format(value) for value in cf_mtx.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in cf_mtx.flatten()/np.sum(cf_mtx)]
box_labels = [f"{v1}\n({v2})" for v1, v2 in zip(group_counts, group_percentages)]
box_labels = np.asarray(box_labels).reshape(6, 6)

plt.figure(figsize = (12, 10))
sns.heatmap(cf_mtx, xticklabels=labels.values(), yticklabels=labels.values(),
           cmap="YlGnBu", fmt="", annot=box_labels)
plt.xlabel('Predicted Classes')
plt.ylabel('True Classes')
plt.show()

"""# **6. Results Interpretation**

**Exploring misclassified images**
"""

errors = (y_true - y_pred != 0)
y_true_errors = y_true[errors]
y_pred_errors = y_pred[errors]

test_images = test_generator.filenames
test_img = np.asarray(test_images)[errors]

fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(12, 10))
idx = 0

for i in range(2):
    for j in range(5):
        idx = np.random.randint(0, len(test_img))
        true_index = y_true_errors[idx]
        true_label = labels[true_index]
        predicted_index = y_pred_errors[idx]
        predicted_label = labels[predicted_index]
        ax[i, j].set_title(f"True Label: {true_label} \n Predicted Label: {predicted_label}")
        img_path = os.path.join(test_dataset, test_img[idx])
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        ax[i, j].imshow(img)
        ax[i, j].axis("off")

plt.tight_layout()
plt.suptitle('Wrong Predictions made on test set', fontsize=20)
plt.show()

"""**Findings:**

Test Loss: 0.488, indicating that, on average, the model's predictions are reasonably close to the actual values.

Test Accuracy: 0.830, suggesting that the model performs well, correctly classifying approximately 83% of the test data.

Precision, Recall, and F1-score: These metrics provide insights into the performance of the model for each class. Some classes like buildings and glacier have slightly lower precision and recall compared to others, indicating room for improvement.

# **Create pickle files for trained CNN model and preprocessing objects**
"""

import pickle

# Save trained CNN model
cnn_model.save('cnn_model.h5')

# Save labels dictionary
with open('labels.pickle', 'wb') as handle:
    pickle.dump(labels, handle, protocol=pickle.HIGHEST_PROTOCOL)

# Save ImageDataGenerator configuration
with open('train_datagen.pickle', 'wb') as handle:
    pickle.dump(train_datagen, handle, protocol=pickle.HIGHEST_PROTOCOL)

# Save test_generator filenames
with open('test_generator_filenames.pickle', 'wb') as handle:
    pickle.dump(test_generator.filenames, handle, protocol=pickle.HIGHEST_PROTOCOL)

"""# **7. Training a Logistic Regression Model**

getting overfitting to train, bt bad accuracy on test data, need to do hyper paramter tuning, done 3-4 times not success yet, need to check more
-bimz
"""

# Importing necessary libraries
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report

# Flatten the images for Logistic Regression
X_train = train_generator[0][0].reshape(train_generator[0][0].shape[0], -1)
y_train = np.argmax(train_generator[0][1], axis=1)

X_test = test_generator[0][0].reshape(test_generator[0][0].shape[0], -1)
y_test = np.argmax(test_generator[0][1], axis=1)

# Scale the data to be between 0 and 1
scaler = MinMaxScaler().fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# Define the hyperparameters
hyperparameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],
                   'penalty': ['l1', 'l2']}

# Initialize logistic regression
logistic = LogisticRegression(solver='saga', tol=0.1)

# Initialize GridSearchCV
grid_cv = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)

# Fit grid_cv and find the best hyperparameters
grid_cv.fit(X_train, y_train)

# Print the best hyperparameters
print('Best Penalty:', grid_cv.best_estimator_.get_params()['penalty'])
print('Best C:', grid_cv.best_estimator_.get_params()['C'])

# Predict the labels
y_pred = grid_cv.predict(X_test)

# Print the classification report
print(classification_report(y_test, y_pred))



pip install streamlit

pip install flask

from flask import Flask, request, jsonify
from tensorflow.keras.models import load_model
import numpy as np
from PIL import Image
import io

app = Flask(__name__)
model = load_model('/content/cnn_model.h5')

@app.route('/predict', methods=['POST'])
def predict():
    if 'file' not in request.files:
        return jsonify({'error': 'No file provided'}), 400
    file = request.files['file']
    image = Image.open(io.BytesIO(file.read()))
    image = image.resize((150, 150))  # Adjust size as needed
    image = np.array(image)
    image = image / 255.0  # Normalize
    image = np.expand_dims(image, axis=0)

    prediction = model.predict(image)
    class_id = np.argmax(prediction)
    return jsonify({'class_id': class_id, 'confidence': float(prediction[0][class_id])})

if __name__ == '__main__':
    app.run(debug=True)

"""# **8. Training Decision Trees Model**"""

from keras.preprocessing.image import ImageDataGenerator
import numpy as np
from skimage.color import rgb2gray
from skimage.feature import local_binary_pattern, hog
from skimage.filters import sobel, gaussian
from skimage.exposure import histogram

# Load features and labels using Pickle
with open('/content/clf_train_features.pkl', 'rb') as f:
    features = pickle.load(f)

with open('/content/clf_train_labels.pkl', 'rb') as f:
    labels = pickle.load(f)

# Paths and Parameters
train_dataset_path = '/content/seg_train/seg_train'
validation_dataset_path = '/content/seg_test/seg_test'

IMG_WIDTH = 128
IMG_HEIGHT = 128
BATCH_SIZE = 32

# Data Generator Configuration
train_datagen = ImageDataGenerator(rescale=1.0/255,  # Normalize pixel values
                                   zoom_range=0.2,    # Zoom in or out by up to 20%
                                   width_shift_range=0.2,    # Shift images horizontally by up to 20% of the width
                                   height_shift_range=0.2,   # Shift images vertically by up to 20% of the height
                                   fill_mode='nearest')      # Fill in missing pixels with the nearest value

train_generator = train_datagen.flow_from_directory(train_dataset_path,
                                                    target_size=(IMG_WIDTH, IMG_HEIGHT),
                                                    batch_size=BATCH_SIZE,
                                                    class_mode='categorical',
                                                    shuffle=True)

def extract_features(image):
    # Convert image to grayscale
    gray_image = rgb2gray(image)

    # Apply Gaussian blur to smooth the image
    smoothed_image = gaussian(gray_image, sigma=1)

    # Local Binary Pattern for texture
    lbp = local_binary_pattern(smoothed_image, P=16, R=2, method='uniform')
    lbp_hist, _ = np.histogram(lbp, density=True, bins=np.arange(0, 18), range=(0, 17))

    # Sobel Edge Detection to capture edges
    edge_sobel = sobel(smoothed_image)
    edge_hist, _ = np.histogram(edge_sobel, density=True, bins=10)

    # Histogram of Oriented Gradients (HOG) for shape and texture
    # Note the use of `channel_axis=-1` to specify that the input is a color image
    hog_features, _ = hog(image, orientations=8, pixels_per_cell=(16, 16),
                          cells_per_block=(1, 1), visualize=True, multichannel=True, channel_axis=-1)

    # Color histogram in the RGB space
    color_hist = np.concatenate([np.histogram(image[:, :, i], bins=32, range=(0, 1), density=True)[0]
                                 for i in range(3)])  # Ensure the range is over all three channels if RGB

    # Combine features
    combined_features = np.concatenate((lbp_hist, edge_hist, hog_features, color_hist))
    return combined_features

# Initialize storage for features and labels
features = []
labels = []
current_batch = 0

from math import ceil

def process_batch(x_batch):
    # Process each image in the batch individually
    return np.array([extract_features(image) for image in x_batch])

# Calculate the total number of batches
total_batches = ceil(train_generator.samples / train_generator.batch_size)

# Extract features from all images
for x_batch, y_batch in train_generator:
    batch_features = process_batch(x_batch)  # Process each image in the batch
    features.append(batch_features)
    labels.append(y_batch)

    current_batch += 1  # Increment the current batch count
    print(f"Processed batch {current_batch} out of {total_batches}")

    # Stop the loop after the last batch
    if current_batch >= total_batches:
        break

# Convert list to numpy arrays
features = np.vstack(features)
labels = np.vstack(labels)

# Convert one-hot encoded labels to integer labels
integer_labels = np.argmax(labels, axis=1)

# Now integer_labels contains integer values from 0 to 5, each representing a class
print(integer_labels.shape)

print(features.shape)
print(integer_labels.shape)

integer_labels

import pickle

# Save features and labels using Pickle
with open('/content/clf_train_features.pkl', 'wb') as f:
    pickle.dump(features, f)

with open('/content/clf_train_labels.pkl', 'wb') as f:
    pickle.dump(integer_labels, f)

from sklearn.model_selection import train_test_split

# Assuming 'features' is your array of extracted features and 'train_labels' are your labels
X_train, X_test, y_train, y_test = train_test_split(features, integer_labels, test_size=0.2, random_state=42)

from sklearn.tree import DecisionTreeClassifier

# Initialize the Decision Tree Classifier
clf = DecisionTreeClassifier(
    criterion='gini',          # Metric used for splitting (alternative: 'entropy')
    splitter='best',           # Strategy used to choose the split at each node (alternative: 'random')
    max_depth=20,              # Maximum depth of the tree to limit tree size and prevent overfitting
    min_samples_split=20,      # Minimum number of samples required to split an internal node
    min_samples_leaf=10,       # Minimum number of samples required to be at a leaf node
    max_features=None,         # Number of features to consider when looking for the best split; None means all features
    max_leaf_nodes=None,       # Maximum number of leaf nodes (None means unlimited)
    min_impurity_decrease=0.01,# A node will be split if this split induces a decrease of the impurity greater than or equal to this value.
    random_state=42            # Ensures the same results are produced each time the model is run
)
# Fit the model on the training data
clf.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, classification_report

# Predict on the test set
y_pred_test = clf.predict(X_test)
y_pred_train = clf.predict(X_train)

# Calculate accuracy for training
accuracy_train = accuracy_score(y_train, y_pred_train)
print(f"Accuracy for training: {accuracy_train}")

# Calculate accuracy for testing
accuracy_test = accuracy_score(y_test, y_pred_test)
print(f"Accuracy for testing: {accuracy_test}")

"""## Model Tunning"""

# Load features and labels using Pickle
with open('/content/clf_train_features.pkl', 'rb') as f:
    features = pickle.load(f)

with open('/content/clf_train_labels.pkl', 'rb') as f:
    labels = pickle.load(f)

"""### PCA"""

from sklearn.decomposition import PCA

pca = PCA(n_components=0.95)
features_reduced = pca.fit_transform(features)

# Check how many features are retained
print("Reduced feature dimensions:", features_reduced.shape)

# Assuming 'integer_labels' is already generated from one-hot labels as previously described
X_train, X_test, y_train, y_test = train_test_split(features_reduced, labels, test_size=0.2, random_state=42)

"""### Random Forest"""

from sklearn.ensemble import RandomForestClassifier

rf_clf = RandomForestClassifier(
    n_estimators=100,  # The number of trees in the forest
    criterion='gini',  # Metric used for splitting (alternative: 'entropy')
    max_depth=None,    # Maximum depth of each tree. None means no limit, which might cause overfitting
    min_samples_split=2,  # Minimum number of samples required to split an internal node
    min_samples_leaf=1,  # Minimum number of samples required to be at a leaf node
    max_features='auto',  # The number of features to consider when looking for the best split; 'auto' means sqrt(n_features)
    random_state=42,  # Ensures the same results are produced each time the model is run
    n_jobs=-1,        # Use all processors for training
    verbose=1         # Controls verbosity of process
)

rf_clf.fit(X_train, y_train)

from sklearn.metrics import accuracy_score

# Predict on the test set
y_pred_test = rf_clf.predict(X_test)
y_pred_train = rf_clf.predict(X_train)

# Calculate accuracy for training
accuracy_train = accuracy_score(y_train, y_pred_train)
print(f"Accuracy for training: {accuracy_train}")

# Calculate accuracy for testing
accuracy_test = accuracy_score(y_test, y_pred_test)
print(f"Accuracy for testing: {accuracy_test}")

"""model is over fitting on training data, creating another random forest model with max_depth set to 10 to reduce overfitting

### Second Iteration
"""

rf_clf_2 = RandomForestClassifier(
    n_estimators=100,  # The number of trees in the forest
    criterion='gini',  # Metric used for splitting (alternative: 'entropy')
    max_depth=10,    # Maximum depth of each tree. None means no limit, which might cause overfitting
    min_samples_split=2,  # Minimum number of samples required to split an internal node
    min_samples_leaf=1,  # Minimum number of samples required to be at a leaf node
    max_features='auto',  # The number of features to consider when looking for the best split; 'auto' means sqrt(n_features)
    random_state=42,  # Ensures the same results are produced each time the model is run
    n_jobs=-1,        # Use all processors for training
    verbose=1         # Controls verbosity of process
)

rf_clf_2.fit(X_train, y_train)

# Predict on the test set
y_pred_test = rf_clf_2.predict(X_test)
y_pred_train = rf_clf_2.predict(X_train)

from sklearn.metrics import accuracy_score

# Calculate accuracy for training
accuracy_train = accuracy_score(y_train, y_pred_train)
print(f"Accuracy for training: {accuracy_train}")

# Calculate accuracy for testing
accuracy_test = accuracy_score(y_test, y_pred_test)
print(f"Accuracy for testing: {accuracy_test}")

"""## Models Evaluation on Validation Set"""

validation_datagen = ImageDataGenerator(rescale=1.0/255)
validation_generator = validation_datagen.flow_from_directory(validation_dataset_path,
                                                             target_size=(IMG_WIDTH, IMG_HEIGHT),
                                                             batch_size=BATCH_SIZE,
                                                             class_mode='categorical',
                                                             shuffle=True)

# Initialize storage for features and labels
validation_features = []
validation_labels = []
v_current_batch = 0

# Calculate the total number of batches
v_total_batches = ceil(validation_generator.samples / validation_generator.batch_size)

# Extract features from all images
for x_batch, y_batch in validation_generator:
    batch_features = process_batch(x_batch)  # Process each image in the batch
    validation_features.append(batch_features)
    validation_labels.append(y_batch)

    current_batch += 1  # Increment the current batch count
    print(f"Processed batch {v_current_batch} out of {v_total_batches}")

    # Stop the loop after the last batch
    if v_current_batch >= v_total_batches:
        break

# Convert list to numpy arrays
features_v = np.vstack(validation_features)
labels_v = np.vstack(validation_labels)

# Convert one-hot encoded labels to integer labels
integer_labels_v = np.argmax(labels_v, axis=1)

validation_features_reduced = pca.transform(features_v)

validation_predictions_clf = clf.predict(features_v)

validation_predictions_rf_clf = rf_clf.predict(validation_features_reduced)

validation_predictions_rf_clf_2 = rf_clf_2.predict(validation_features_reduced)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import pandas as pd

# Metrics for clf
precision_clf = precision_score(integer_labels_v, validation_predictions_clf, average='weighted')
recall_clf = recall_score(integer_labels_v, validation_predictions_clf, average='weighted')
f1_clf = f1_score(integer_labels_v, validation_predictions_clf, average='weighted')

# Metrics for rf_clf
precision_rf_clf = precision_score(integer_labels_v, validation_predictions_rf_clf, average='weighted')
recall_rf_clf = recall_score(integer_labels_v, validation_predictions_rf_clf, average='weighted')
f1_rf_clf = f1_score(integer_labels_v, validation_predictions_rf_clf, average='weighted')

# Metrics for rf_clf_2
precision_rf_clf_2 = precision_score(integer_labels_v, validation_predictions_rf_clf_2, average='weighted')
recall_rf_clf_2 = recall_score(integer_labels_v, validation_predictions_rf_clf_2, average='weighted')
f1_rf_clf_2 = f1_score(integer_labels_v, validation_predictions_rf_clf_2, average='weighted')

# Creating a DataFrame
results_df = pd.DataFrame({
    'Model': ['Decision Tree', 'Random Forest (with PCA)', 'Random Forest (with PCA tuned)'],
    'Accuracy': [accuracy_clf, accuracy_rf_clf, accuracy_rf_clf_2],
    'Precision': [precision_clf, precision_rf_clf, precision_rf_clf_2],
    'Recall': [recall_clf, recall_rf_clf, recall_rf_clf_2],
    'F1 Score': [f1_clf, f1_rf_clf, f1_rf_clf_2]
})

results_df

# Save the PCA model
with open('pca_model.pkl', 'wb') as file:
    pickle.dump(pca, file)

# Save the decision tree classifier (clf)
with open('decision_tree_clf.pkl', 'wb') as file:
    pickle.dump(clf, file)

# Save the first random forest classifier (rf_clf)
with open('random_forest_clf_1.pkl', 'wb') as file:
    pickle.dump(rf_clf, file)

# Save the second random forest classifier (rf_clf_2)
with open('random_forest_clf_2.pkl', 'wb') as file:
    pickle.dump(rf_clf_2, file)

# Save original validation features (features_v)
with open('validation_features.pkl', 'wb') as file:
    pickle.dump(features_v, file)

# Save validation labels (labels_v)
with open('validation_labels.pkl', 'wb') as file:
    pickle.dump(labels_v, file)

# Save PCA-reduced training features (features_reduced)
with open('features_reduced.pkl', 'wb') as file:
    pickle.dump(features_reduced, file)

# Save PCA-reduced validation features (validation_features_reduced)
with open('validation_features_reduced.pkl', 'wb') as file:
    pickle.dump(validation_features_reduced, file)